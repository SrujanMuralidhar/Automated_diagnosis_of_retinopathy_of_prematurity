{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image\n",
    "    transforms.RandomHorizontalFlip(),  # Data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir = 'Data_histEq'  # Replace with your directory path\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size   # 20% for validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for train and validation sets\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "}\n",
    "\n",
    "num_classes = len(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1328 333\n"
     ]
    }
   ],
   "source": [
    "print(train_size,val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class number: 0, Class name: FVR\n",
      "Class number: 1, Class name: Stage 1\n",
      "Class number: 2, Class name: Stage 2\n",
      "Class number: 3, Class name: Stage 3\n",
      "Class number: 4, Class name: TAR\n"
     ]
    }
   ],
   "source": [
    "# Print class numbers and their corresponding class names\n",
    "for idx, class_name in enumerate(dataset.classes):\n",
    "    print(f\"Class number: {idx}, Class name: {class_name}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Modify the last fully connected layer for the number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Check if GPU is available and move the model to GPU if possible\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "writer = SummaryWriter('runs/stage_classification_experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Collect predictions and labels for Cohen's Kappa\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Calculate Cohen's Kappa for validation phase\n",
    "            if phase == 'val':\n",
    "                kappa = cohen_kappa_score(all_preds, all_labels)\n",
    "                print(f'{phase} Cohen\\'s Kappa: {kappa:.4f}')\n",
    "\n",
    "            # Log metrics to TensorBoard\n",
    "            writer.add_scalar(f'{phase} Loss', epoch_loss, epoch)\n",
    "            writer.add_scalar(f'{phase} Accuracy', epoch_acc, epoch)\n",
    "            if phase == 'val':\n",
    "                writer.add_scalar(f'{phase} Cohen\\'s Kappa', kappa, epoch)\n",
    "\n",
    "            # If it's the validation phase, save the best model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), 'ResNet_Model.pth')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.3034 Acc: 0.4684\n",
      "val Loss: 1.1488 Acc: 0.5345\n",
      "val Cohen's Kappa: 0.3611\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.0139 Acc: 0.6054\n",
      "val Loss: 1.2179 Acc: 0.4985\n",
      "val Cohen's Kappa: 0.3283\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.9653 Acc: 0.6054\n",
      "val Loss: 1.2097 Acc: 0.5616\n",
      "val Cohen's Kappa: 0.3735\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.8636 Acc: 0.6627\n",
      "val Loss: 0.8963 Acc: 0.6607\n",
      "val Cohen's Kappa: 0.5354\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.8023 Acc: 0.6867\n",
      "val Loss: 0.9559 Acc: 0.6276\n",
      "val Cohen's Kappa: 0.4872\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.6993 Acc: 0.7410\n",
      "val Loss: 1.1843 Acc: 0.6276\n",
      "val Cohen's Kappa: 0.4643\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.7100 Acc: 0.7259\n",
      "val Loss: 0.9389 Acc: 0.6096\n",
      "val Cohen's Kappa: 0.4812\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.5718 Acc: 0.7816\n",
      "val Loss: 1.3995 Acc: 0.5766\n",
      "val Cohen's Kappa: 0.4275\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.5253 Acc: 0.8110\n",
      "val Loss: 1.0110 Acc: 0.6577\n",
      "val Cohen's Kappa: 0.5321\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.5258 Acc: 0.7892\n",
      "val Loss: 1.2697 Acc: 0.6096\n",
      "val Cohen's Kappa: 0.4789\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.4529 Acc: 0.8321\n",
      "val Loss: 1.1226 Acc: 0.6366\n",
      "val Cohen's Kappa: 0.5019\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.3898 Acc: 0.8517\n",
      "val Loss: 1.1875 Acc: 0.6877\n",
      "val Cohen's Kappa: 0.5642\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.3365 Acc: 0.8765\n",
      "val Loss: 1.1275 Acc: 0.6727\n",
      "val Cohen's Kappa: 0.5531\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.2509 Acc: 0.9044\n",
      "val Loss: 1.2417 Acc: 0.6517\n",
      "val Cohen's Kappa: 0.5339\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.2775 Acc: 0.9074\n",
      "val Loss: 1.3738 Acc: 0.6186\n",
      "val Cohen's Kappa: 0.5075\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.2765 Acc: 0.8961\n",
      "val Loss: 1.2917 Acc: 0.6757\n",
      "val Cohen's Kappa: 0.5559\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.2335 Acc: 0.9104\n",
      "val Loss: 1.2197 Acc: 0.6727\n",
      "val Cohen's Kappa: 0.5501\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.1696 Acc: 0.9398\n",
      "val Loss: 1.1137 Acc: 0.6877\n",
      "val Cohen's Kappa: 0.5838\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.0907 Acc: 0.9729\n",
      "val Loss: 0.9402 Acc: 0.7327\n",
      "val Cohen's Kappa: 0.6439\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.0732 Acc: 0.9782\n",
      "val Loss: 1.1938 Acc: 0.6967\n",
      "val Cohen's Kappa: 0.5915\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.1368 Acc: 0.9518\n",
      "val Loss: 1.5051 Acc: 0.6697\n",
      "val Cohen's Kappa: 0.5480\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.2401 Acc: 0.9149\n",
      "val Loss: 1.6844 Acc: 0.5736\n",
      "val Cohen's Kappa: 0.4290\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.1650 Acc: 0.9375\n",
      "val Loss: 1.4988 Acc: 0.6456\n",
      "val Cohen's Kappa: 0.5077\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.1358 Acc: 0.9571\n",
      "val Loss: 1.1481 Acc: 0.6937\n",
      "val Cohen's Kappa: 0.5850\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.1134 Acc: 0.9601\n",
      "val Loss: 1.3863 Acc: 0.6336\n",
      "val Cohen's Kappa: 0.5037\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.0886 Acc: 0.9699\n",
      "val Loss: 1.2691 Acc: 0.6937\n",
      "val Cohen's Kappa: 0.5804\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.0691 Acc: 0.9752\n",
      "val Loss: 1.3061 Acc: 0.7147\n",
      "val Cohen's Kappa: 0.6128\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.0641 Acc: 0.9774\n",
      "val Loss: 1.1037 Acc: 0.7508\n",
      "val Cohen's Kappa: 0.6661\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.0548 Acc: 0.9834\n",
      "val Loss: 1.1976 Acc: 0.7327\n",
      "val Cohen's Kappa: 0.6359\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.0584 Acc: 0.9782\n",
      "val Loss: 1.3536 Acc: 0.7117\n",
      "val Cohen's Kappa: 0.6018\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.0588 Acc: 0.9789\n",
      "val Loss: 1.2164 Acc: 0.7237\n",
      "val Cohen's Kappa: 0.6295\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.0558 Acc: 0.9804\n",
      "val Loss: 1.4532 Acc: 0.7177\n",
      "val Cohen's Kappa: 0.6207\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.0756 Acc: 0.9767\n",
      "val Loss: 1.2868 Acc: 0.6667\n",
      "val Cohen's Kappa: 0.5562\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.0887 Acc: 0.9654\n",
      "val Loss: 1.7215 Acc: 0.6697\n",
      "val Cohen's Kappa: 0.5379\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.1186 Acc: 0.9541\n",
      "val Loss: 1.6898 Acc: 0.6456\n",
      "val Cohen's Kappa: 0.5244\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.1359 Acc: 0.9511\n",
      "val Loss: 1.6725 Acc: 0.6486\n",
      "val Cohen's Kappa: 0.5319\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.0941 Acc: 0.9676\n",
      "val Loss: 1.4996 Acc: 0.6697\n",
      "val Cohen's Kappa: 0.5556\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.0496 Acc: 0.9804\n",
      "val Loss: 1.4277 Acc: 0.7027\n",
      "val Cohen's Kappa: 0.5919\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.0272 Acc: 0.9910\n",
      "val Loss: 1.4629 Acc: 0.7087\n",
      "val Cohen's Kappa: 0.6011\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.0353 Acc: 0.9895\n",
      "val Loss: 1.6011 Acc: 0.6937\n",
      "val Cohen's Kappa: 0.5776\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.0568 Acc: 0.9797\n",
      "val Loss: 1.4919 Acc: 0.6817\n",
      "val Cohen's Kappa: 0.5617\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.0495 Acc: 0.9887\n",
      "val Loss: 1.4709 Acc: 0.6877\n",
      "val Cohen's Kappa: 0.5737\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.0312 Acc: 0.9895\n",
      "val Loss: 1.4539 Acc: 0.6697\n",
      "val Cohen's Kappa: 0.5471\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.0197 Acc: 0.9955\n",
      "val Loss: 1.3859 Acc: 0.7117\n",
      "val Cohen's Kappa: 0.6104\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.0272 Acc: 0.9902\n",
      "val Loss: 1.4045 Acc: 0.6937\n",
      "val Cohen's Kappa: 0.5839\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.0246 Acc: 0.9910\n",
      "val Loss: 1.4148 Acc: 0.7267\n",
      "val Cohen's Kappa: 0.6364\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.0146 Acc: 0.9947\n",
      "val Loss: 1.6219 Acc: 0.6877\n",
      "val Cohen's Kappa: 0.5728\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.0251 Acc: 0.9932\n",
      "val Loss: 1.6167 Acc: 0.6787\n",
      "val Cohen's Kappa: 0.5594\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.0083 Acc: 0.9992\n",
      "val Loss: 1.1828 Acc: 0.7267\n",
      "val Cohen's Kappa: 0.6289\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.0035 Acc: 1.0000\n",
      "val Loss: 1.3901 Acc: 0.7297\n",
      "val Cohen's Kappa: 0.6318\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "def extract_embeddings(dataloader, model):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    labels_list = []\n",
    "    image_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass through all layers except the final fully connected (fc) layer\n",
    "            features = model.conv1(inputs)\n",
    "            features = model.bn1(features)\n",
    "            features = model.relu(features)\n",
    "            features = model.maxpool(features)\n",
    "            features = model.layer1(features)\n",
    "            features = model.layer2(features)\n",
    "            features = model.layer3(features)\n",
    "            features = model.layer4(features)\n",
    "            features = model.avgpool(features)\n",
    "            features = torch.flatten(features, 1)  # Flatten to (batch_size, feature_size)\n",
    "\n",
    "            embeddings.append(features.cpu())  # Store the features/embeddings\n",
    "            labels_list.append(labels.cpu())   # Store corresponding labels\n",
    "            image_list.append(inputs.cpu())    # Save images as numpy arrays\n",
    "\n",
    "    return torch.cat(embeddings), torch.cat(labels_list), torch.cat(image_list)\n",
    "\n",
    "\n",
    "# Extract embeddings, labels, and images\n",
    "embeddings, labels, images = extract_embeddings(dataloaders['val'], model)\n",
    "\n",
    "# Log embeddings to TensorBoard projector\n",
    "def log_embeddings_to_projector(writer, embeddings, labels, images, class_names):\n",
    "    writer.add_embedding(embeddings, metadata=labels, label_img=images)\n",
    "    \n",
    "    # Save class names as a separate metadata file\n",
    "    class_metadata_path = os.path.join('runs', 'class_metadata.tsv')\n",
    "    with open(class_metadata_path, 'w') as f:\n",
    "        for label in class_names:\n",
    "            f.write(f'{label}\\n')\n",
    "\n",
    "    # Add projector config\n",
    "    writer.add_embedding(embeddings, metadata=labels.tolist(), label_img=images)\n",
    "\n",
    "# Log embeddings to TensorBoard projector\n",
    "log_embeddings_to_projector(writer, embeddings, labels, images, dataset.classes)\n",
    "\n",
    "# Close the TensorBoard writer after training is complete\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
