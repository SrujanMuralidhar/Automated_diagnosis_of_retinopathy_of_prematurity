{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate\n",
    "from skimage import img_as_float\n",
    "from skimage.filters import gabor\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import model\n",
    "import cv2\n",
    "from tqdm import tqdm  # For progress bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = r\"pipeline-output\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (512, 512)\n",
    "\n",
    "\n",
    "path = r\"Data\\Stage 3\\2.png\"\n",
    "\n",
    "original_image = cv2.imread(path)\n",
    "original_image = cv2.resize(original_image, size, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Non-Temporal Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gabor Filter - used for Ridge Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def enhance_edges(image):\n",
    "    image = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    image = np.uint8(image)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    # Convert the image to float for Sato filter\n",
    "    image_float = img_as_float(image)\n",
    "    # Define the structuring element (kernel) for morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 50))\n",
    "    # Apply the Top-Hat transformation\n",
    "    top_hat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel) \n",
    "    # Apply the Bottom-Hat transformation\n",
    "    bottom_hat = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)\n",
    "    # Enhance the image by adding Top-Hat and subtracting Bottom-Hat\n",
    "    enhanced_image = cv2.add(image, top_hat)   # Add Top-Hat to enhance bright regions\n",
    "    enhanced_image = cv2.subtract(enhanced_image, bottom_hat)  # Subtract Bottom-Hat to enhance dark regions\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "def gab(image):\n",
    "    img = enhance_edges(image)\n",
    "    filt_real, filt_imaginary = gabor(img,1/4,30,sigma_x=1,sigma_y=1)\n",
    "    # img = Image.fromarray(filt_real)\n",
    "    return filt_real\n",
    "\n",
    "def refine_edges(image):\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    center = (int(image.shape[1] / 2), int(image.shape[0] / 2))\n",
    "    radius = image.shape[1]//2 - 1\n",
    "    cv2.circle(mask, center, radius, 255, -1)\n",
    "    result = cv2.bitwise_and(mask,image)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gabor Filter\n",
    "\n",
    "gab_image = gab(original_image)\n",
    "gab_image = refine_edges(gab_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gab_image_path = os.path.join(output_folder, \"gabor_image.png\")\n",
    "cv2.imwrite(gab_image_path,gab_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Adaptive Siigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_correction(image, k=10, x0=0.5):\n",
    "    # Normalize the image\n",
    "    normalized_img = image / 255.0\n",
    "    # Apply the sigmoid function\n",
    "    sigmoid_img = 1 / (1 + np.exp(-k * (normalized_img - x0)))\n",
    "    # Scale back to original range\n",
    "    corrected_img = (sigmoid_img * 255).astype(np.uint8)\n",
    "    return corrected_img\n",
    "\n",
    "\n",
    "def adaptive_sigmoid(image):\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    center = (int(image.shape[1] / 2), int(image.shape[0] / 2))\n",
    "    radius = image.shape[1]//2\n",
    "    cv2.circle(mask, center, radius, 255, -1)\n",
    "    hist = cv2.calcHist([image], [1], mask, [256], [0, 256])\n",
    "    # Calculate cumulative distribution function (CDF)\n",
    "    cdf = hist.cumsum()\n",
    "    # Normalize CDF\n",
    "    cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "    # Find the intensity level where CDF reaches 50% of the total pixel count\n",
    "    total_pixels = cdf[-1]\n",
    "    x_0 = np.searchsorted(cdf, total_pixels * 0.5)/255\n",
    "    k = 15\n",
    "    sig = sigmoid_correction(image,k,x_0)\n",
    "    return sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_sigmoid_image = adaptive_sigmoid(original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptive_sigmoid_image_path = os.path.join(output_folder, \"adaptive_sigmoid_image.png\")\n",
    "cv2.imwrite(adaptive_sigmoid_image_path,adaptive_sigmoid_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the Blood Vessel and Ridge Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import model\n",
    "import cv2\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Parse mask for saving\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "    return mask\n",
    "\n",
    "# Load models\n",
    "bv_model = model.build_unet()\n",
    "bv_model.load_state_dict(torch.load(r'files\\bv_perCHistEq_kaggle_data.pth', map_location=torch.device('cuda')))\n",
    "bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "bv_model.eval()\n",
    "\n",
    "ridge_model = model.build_unet()\n",
    "ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "ridge_model = ridge_model.cuda()  # Load model on GPU if available\n",
    "ridge_model.eval()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load and resize the image\n",
    "def load_image(image_path):\n",
    "    if image_path.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image.resize((512, 512))\n",
    "        image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "        return image\n",
    "    \n",
    "# Get mask prediction\n",
    "def get_prediction(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "        output = np.squeeze(output, axis=0)\n",
    "        output = output > 0.5\n",
    "        output = np.array(output, dtype=np.uint8)\n",
    "        return output\n",
    "\n",
    "def sigmoid_correction(image, k=10, x0=0.5):\n",
    "    # Normalize the image\n",
    "    normalized_img = image / 255.0\n",
    "    # Apply the sigmoid function\n",
    "    sigmoid_img = 1 / (1 + np.exp(-k * (normalized_img - x0)))\n",
    "    # Scale back to original range\n",
    "    corrected_img = (sigmoid_img * 255).astype(np.uint8)\n",
    "    return corrected_img\n",
    "\n",
    "def adaptive_sigmoid(image):\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    center = (int(image.shape[1] / 2), int(image.shape[0] / 2))\n",
    "    radius = image.shape[1]//2\n",
    "    cv2.circle(mask, center, radius, 255, -1)\n",
    "    hist = cv2.calcHist([image], [1], mask, [256], [0, 256])\n",
    "    # Calculate cumulative distribution function (CDF)\n",
    "    cdf = hist.cumsum()\n",
    "    # Normalize CDF\n",
    "    cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "    # Find the intensity level where CDF reaches 50% of the total pixel count\n",
    "    total_pixels = cdf[-1]\n",
    "    x_0 = np.searchsorted(cdf, total_pixels * 0.5)/255\n",
    "    k = 15\n",
    "    sig = sigmoid_correction(image, k, x_0)\n",
    "    return sig\n",
    "\n",
    "def apply_hist_eq(image):\n",
    "    # Split the image into its respective channels\n",
    "    channels = cv2.split(image)\n",
    "    # Apply histogram equalization on each channel\n",
    "    equalized_channels = [cv2.equalizeHist(channel) for channel in channels]\n",
    "    # Merge the equalized channels back into a single image\n",
    "    equalized_image = cv2.merge(equalized_channels)\n",
    "    return equalized_image\n",
    "\n",
    "# Superpose masks on the original image with sigmoid correction\n",
    "def superpose_masks(original_image, bv_mask, ridge_mask):\n",
    "    # Convert original image to NumPy\n",
    "    original_image_np = np.array(original_image)\n",
    "    \n",
    "    # Apply sigmoid correction to the original image\n",
    "    corrected_image_np = adaptive_sigmoid(original_image_np)\n",
    "    \n",
    "    # Initialize the combined mask with 3 channels (for RGB)\n",
    "    combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # COLOR coding for the MASKS\n",
    "    #-----------------------------------------------------------------------------\n",
    "    combined_mask[bv_mask == 1] = [179, 2, 2]  \n",
    "    combined_mask[ridge_mask == 1] = [25, 10, 242]  \n",
    "    #------------------------------------------------------------------------------\n",
    "    # Superpose the masks on the sigmoid-corrected original image\n",
    "    superposed_image = corrected_image_np.copy()\n",
    "    mask_indices = combined_mask > 0\n",
    "    superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "    \n",
    "    return Image.fromarray(superposed_image)\n",
    "\n",
    "# Process a single image\n",
    "def process_single_image(bv_image_path, ridge_image_path, output_path):\n",
    "    # Load the images and resize if necessary\n",
    "    bv_image_tensor = load_image(bv_image_path)\n",
    "    ridge_image_tensor = load_image(ridge_image_path)\n",
    "    original_image = Image.open(bv_image_path).convert('RGB').resize((512, 512))\n",
    "\n",
    "    # Generate masks\n",
    "    bv_mask = get_prediction(bv_model, bv_image_tensor)\n",
    "    ridge_mask = get_prediction(ridge_model, ridge_image_tensor)\n",
    "\n",
    "    # Superpose the masks onto the original image\n",
    "    superposed_image = superpose_masks(original_image, bv_mask, ridge_mask)\n",
    "\n",
    "    # Save the output image\n",
    "    superposed_image.save(output_path)\n",
    "    print(f\"Superposed image saved at {output_path}\")\n",
    "\n",
    "# Single image input and output paths\n",
    "bv_image_path = r'path\\to\\blood_vessel_image.png'\n",
    "ridge_image_path = r'path\\to\\ridge_image.png'\n",
    "output_path = r'path\\to\\output_superposed_image.png'\n",
    "\n",
    "# Process the single image\n",
    "process_single_image(bv_image_path, ridge_image_path, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
