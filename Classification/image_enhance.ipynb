{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply HistEQ on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def histogram_equalization(img):\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    if img_array.ndim == 2:  # Grayscale\n",
    "        img_array = cv2.equalizeHist(img_array)\n",
    "    else:  # Color image\n",
    "        r, g, b = cv2.split(img_array)\n",
    "        r_eq = cv2.equalizeHist(r)\n",
    "        g_eq = cv2.equalizeHist(g)\n",
    "        b_eq = cv2.equalizeHist(b)\n",
    "        img_array = cv2.merge([r_eq, g_eq, b_eq])\n",
    "    \n",
    "    img_eq = Image.fromarray(img_array)\n",
    "    return img_eq\n",
    "\n",
    "def process_images(src_folder, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    for root, dirs, files in os.walk(src_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                src_path = os.path.join(root, file)\n",
    "                dest_path = os.path.join(dest_folder, os.path.relpath(src_path, src_folder))\n",
    "                \n",
    "                # Create destination directories if they do not exist\n",
    "                os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "                \n",
    "                # Open image\n",
    "                img = Image.open(src_path)\n",
    "                \n",
    "                # Apply histogram equalization\n",
    "                img_eq = histogram_equalization(img)\n",
    "                \n",
    "                # Save the processed image\n",
    "                img_eq.save(dest_path)\n",
    "\n",
    "# Example usage\n",
    "src_folder = 'Data'\n",
    "dest_folder = 'Data_histEq'\n",
    "process_images(src_folder, dest_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram EQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in color\n",
    "path = r'Data/Stage 1/FHPL_83-2022_20220922130851_20221020114517_Image_02_0008_2022-10-20_11-46-18-339_1526.png'\n",
    "image = cv2.imread(path)\n",
    "\n",
    "# Convert the image from BGR to RGB for correct display\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 1. Perform histogram equalization on the whole image\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "equalized_full = cv2.equalizeHist(image_gray)\n",
    "\n",
    "# 2. Apply histogram equalization on individual channels\n",
    "r, g, b = cv2.split(image_rgb)\n",
    "\n",
    "equalized_r = cv2.equalizeHist(r)\n",
    "equalized_g = cv2.equalizeHist(g)\n",
    "equalized_b = cv2.equalizeHist(b)\n",
    "\n",
    "# 3. Combine two different channels and show\n",
    "combined_rg = cv2.merge([equalized_r, equalized_g, b])  # Combine R and G\n",
    "combined_gb = cv2.merge([r, equalized_g, equalized_b])  # Combine G and B\n",
    "combined_rb = cv2.merge([equalized_r, g, equalized_b])  # Combine R and B\n",
    "\n",
    "# 4. Combine all three equalized channels\n",
    "combined_rgb_equalized = cv2.merge([equalized_r, equalized_g, equalized_b])\n",
    "\n",
    "# Plot the results\n",
    "fig, axs = plt.subplots(4, 3, figsize=(12, 16))\n",
    "\n",
    "# Original image\n",
    "axs[0, 0].imshow(image_rgb)\n",
    "axs[0, 0].set_title('Original Image')\n",
    "\n",
    "# Grayscale equalized\n",
    "axs[0, 1].imshow(equalized_full, cmap='gray')\n",
    "axs[0, 1].set_title('Equalized (Grayscale)')\n",
    "\n",
    "# Individual channel equalized\n",
    "axs[1, 0].imshow(equalized_r, cmap='gray')\n",
    "axs[1, 0].set_title('Equalized Red Channel')\n",
    "\n",
    "axs[1, 1].imshow(equalized_g, cmap='gray')\n",
    "axs[1, 1].set_title('Equalized Green Channel')\n",
    "\n",
    "axs[1, 2].imshow(equalized_b, cmap='gray')\n",
    "axs[1, 2].set_title('Equalized Blue Channel')\n",
    "\n",
    "# Combining two channels\n",
    "axs[2, 0].imshow(combined_rg)\n",
    "axs[2, 0].set_title('Combined Equalized R and G')\n",
    "\n",
    "axs[2, 1].imshow(combined_gb)\n",
    "axs[2, 1].set_title('Combined Equalized G and B')\n",
    "\n",
    "axs[2, 2].imshow(combined_rb)\n",
    "axs[2, 2].set_title('Combined Equalized R and B')\n",
    "\n",
    "# All three channels equalized\n",
    "axs[3, 1].imshow(combined_rgb_equalized)\n",
    "axs[3, 1].set_title('Combined Equalized RGB')\n",
    "\n",
    "# Remove axis\n",
    "for ax in axs.flat:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in color\n",
    "path = r'Data/Stage 1/FHPL_83-2022_20220922130851_20221020114517_Image_02_0008_2022-10-20_11-46-18-339_1526.png'\n",
    "image = cv2.imread(path)\n",
    "\n",
    "# Convert the image from BGR to RGB for correct display\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create a CLAHE object (you can set the clipLimit and tileGridSize)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "# 1. Perform CLAHE on the whole image\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "clahe_full = clahe.apply(image_gray)\n",
    "\n",
    "# 2. Apply CLAHE on individual channels\n",
    "r, g, b = cv2.split(image_rgb)\n",
    "\n",
    "clahe_r = clahe.apply(r)\n",
    "clahe_g = clahe.apply(g)\n",
    "clahe_b = clahe.apply(b)\n",
    "\n",
    "# 3. Combine two different channels and show\n",
    "combined_rg = cv2.merge([clahe_r, clahe_g, b])  # Combine CLAHE R and G\n",
    "combined_gb = cv2.merge([r, clahe_g, clahe_b])  # Combine CLAHE G and B\n",
    "combined_rb = cv2.merge([clahe_r, g, clahe_b])  # Combine CLAHE R and B\n",
    "\n",
    "# 4. Combine all three CLAHE channels\n",
    "combined_rgb_clahe = cv2.merge([clahe_r, clahe_g, clahe_b])\n",
    "\n",
    "# Plot the results\n",
    "fig, axs = plt.subplots(4, 3, figsize=(12, 16))\n",
    "\n",
    "# Original image\n",
    "axs[0, 0].imshow(image_rgb)\n",
    "axs[0, 0].set_title('Original Image')\n",
    "\n",
    "# Grayscale CLAHE\n",
    "axs[0, 1].imshow(clahe_full, cmap='gray')\n",
    "axs[0, 1].set_title('CLAHE (Grayscale)')\n",
    "\n",
    "# Individual channel CLAHE\n",
    "axs[1, 0].imshow(clahe_r, cmap='gray')\n",
    "axs[1, 0].set_title('CLAHE Red Channel')\n",
    "\n",
    "axs[1, 1].imshow(clahe_g, cmap='gray')\n",
    "axs[1, 1].set_title('CLAHE Green Channel')\n",
    "\n",
    "axs[1, 2].imshow(clahe_b, cmap='gray')\n",
    "axs[1, 2].set_title('CLAHE Blue Channel')\n",
    "\n",
    "# Combining two channels\n",
    "axs[2, 0].imshow(combined_rg)\n",
    "axs[2, 0].set_title('Combined CLAHE R and G')\n",
    "\n",
    "axs[2, 1].imshow(combined_gb)\n",
    "axs[2, 1].set_title('Combined CLAHE G and B')\n",
    "\n",
    "axs[2, 2].imshow(combined_rb)\n",
    "axs[2, 2].set_title('Combined CLAHE R and B')\n",
    "\n",
    "# All three channels CLAHE\n",
    "axs[3, 1].imshow(combined_rgb_clahe)\n",
    "axs[3, 1].set_title('Combined CLAHE RGB')\n",
    "\n",
    "# Remove axis\n",
    "for ax in axs.flat:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hist EQ followed by CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in color\n",
    "path = r'Data/Stage 1/FHPL_83-2022_20220922130851_20221020114517_Image_02_0008_2022-10-20_11-46-18-339_1526.png'\n",
    "image = cv2.imread(path)\n",
    "\n",
    "# Convert the image from BGR to RGB for correct display\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 1. Perform histogram equalization on the whole image\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "equalized_full = cv2.equalizeHist(image_gray)\n",
    "\n",
    "# 2. Apply histogram equalization on individual channels\n",
    "r, g, b = cv2.split(image_rgb)\n",
    "\n",
    "equalized_r = cv2.equalizeHist(r)\n",
    "equalized_g = cv2.equalizeHist(g)\n",
    "equalized_b = cv2.equalizeHist(b)\n",
    "\n",
    "# 3. Combine two different channels and show\n",
    "combined_rg = cv2.merge([equalized_r, equalized_g, b])  # Combine R and G\n",
    "combined_gb = cv2.merge([r, equalized_g, equalized_b])  # Combine G and B\n",
    "combined_rb = cv2.merge([equalized_r, g, equalized_b])  # Combine R and B\n",
    "\n",
    "# 4. Combine all three equalized channels\n",
    "combined_rgb_equalized = cv2.merge([equalized_r, equalized_g, equalized_b])\n",
    "\n",
    "# Perform CLAHE\n",
    "clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(32,32))\n",
    "\n",
    "# CLAHE for grayscale\n",
    "clahe_full = clahe.apply(image_gray)\n",
    "\n",
    "# CLAHE on individual channels\n",
    "clahe_r = clahe.apply(equalized_r)\n",
    "clahe_g = clahe.apply(equalized_g)\n",
    "clahe_b = clahe.apply(equalized_b)\n",
    "\n",
    "# Combine CLAHE channels\n",
    "combined_rg_clahe = cv2.merge([clahe_r, clahe_g, b])  # CLAHE on R and G\n",
    "combined_gb_clahe = cv2.merge([r, clahe_g, clahe_b])  # CLAHE on G and B\n",
    "combined_rb_clahe = cv2.merge([clahe_r, g, clahe_b])  # CLAHE on R and B\n",
    "combined_rgb_clahe = cv2.merge([clahe_r, clahe_g, clahe_b])  # CLAHE on all channels\n",
    "\n",
    "# Plot the results\n",
    "fig, axs = plt.subplots(6, 3, figsize=(12, 24))\n",
    "\n",
    "# Original image\n",
    "axs[0, 0].imshow(image_rgb)\n",
    "axs[0, 0].set_title('Original Image')\n",
    "\n",
    "# Grayscale equalized\n",
    "axs[0, 1].imshow(equalized_full, cmap='gray')\n",
    "axs[0, 1].set_title('Equalized (Grayscale)')\n",
    "\n",
    "# CLAHE grayscale\n",
    "axs[0, 2].imshow(clahe_full, cmap='gray')\n",
    "axs[0, 2].set_title('CLAHE (Grayscale)')\n",
    "\n",
    "# Individual channel equalized\n",
    "axs[1, 0].imshow(equalized_r, cmap='gray')\n",
    "axs[1, 0].set_title('Equalized Red Channel')\n",
    "\n",
    "axs[1, 1].imshow(equalized_g, cmap='gray')\n",
    "axs[1, 1].set_title('Equalized Green Channel')\n",
    "\n",
    "axs[1, 2].imshow(equalized_b, cmap='gray')\n",
    "axs[1, 2].set_title('Equalized Blue Channel')\n",
    "\n",
    "# CLAHE individual channels\n",
    "axs[2, 0].imshow(clahe_r, cmap='gray')\n",
    "axs[2, 0].set_title('CLAHE Red Channel')\n",
    "\n",
    "axs[2, 1].imshow(clahe_g, cmap='gray')\n",
    "axs[2, 1].set_title('CLAHE Green Channel')\n",
    "\n",
    "axs[2, 2].imshow(clahe_b, cmap='gray')\n",
    "axs[2, 2].set_title('CLAHE Blue Channel')\n",
    "\n",
    "# Combining two channels equalized\n",
    "axs[3, 0].imshow(combined_rg)\n",
    "axs[3, 0].set_title('Combined Equalized R and G')\n",
    "\n",
    "axs[3, 1].imshow(combined_gb)\n",
    "axs[3, 1].set_title('Combined Equalized G and B')\n",
    "\n",
    "axs[3, 2].imshow(combined_rb)\n",
    "axs[3, 2].set_title('Combined Equalized R and B')\n",
    "\n",
    "# Combining two channels CLAHE\n",
    "axs[4, 0].imshow(combined_rg_clahe)\n",
    "axs[4, 0].set_title('Combined CLAHE R and G')\n",
    "\n",
    "axs[4, 1].imshow(combined_gb_clahe)\n",
    "axs[4, 1].set_title('Combined CLAHE G and B')\n",
    "\n",
    "axs[4, 2].imshow(combined_rb_clahe)\n",
    "axs[4, 2].set_title('Combined CLAHE R and B')\n",
    "\n",
    "# All three channels equalized\n",
    "axs[5, 0].imshow(combined_rgb_equalized)\n",
    "axs[5, 0].set_title('Combined Equalized RGB')\n",
    "\n",
    "# All three channels CLAHE\n",
    "axs[5, 1].imshow(combined_rgb_clahe)\n",
    "axs[5, 1].set_title('Combined CLAHE RGB')\n",
    "\n",
    "# Remove axis\n",
    "for ax in axs.flat:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GABOR filter on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 2000/2000 [00:55<00:00, 35.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate\n",
    "from skimage import img_as_float\n",
    "from skimage.filters import gabor\n",
    "from PIL import Image\n",
    "\n",
    "size = (512, 512)\n",
    "\n",
    "def sigmoid_correction(image, k=10, x0=0.5):\n",
    "    # Normalize the image\n",
    "    normalized_img = image / 255.0\n",
    "    # Apply the sigmoid function\n",
    "    sigmoid_img = 1 / (1 + np.exp(-k * (normalized_img - x0)))\n",
    "    # Scale back to original range\n",
    "    corrected_img = (sigmoid_img * 255).astype(np.uint8)\n",
    "    return corrected_img\n",
    "\n",
    "def adaptive_sigmoid(image):\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    center = (int(image.shape[1] / 2), int(image.shape[0] / 2))\n",
    "    radius = image.shape[1] // 2\n",
    "    cv2.circle(mask, center, radius, 255, -1)\n",
    "    hist = cv2.calcHist([image], [1], mask, [256], [0, 256])\n",
    "    # Calculate cumulative distribution function (CDF)\n",
    "    cdf = hist.cumsum()\n",
    "    # Normalize CDF\n",
    "    cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "    # Find the intensity level where CDF reaches 50% of the total pixel count\n",
    "    total_pixels = cdf[-1]\n",
    "    x_0 = np.searchsorted(cdf, total_pixels * 0.5) / 255\n",
    "    k = 15\n",
    "    sig = sigmoid_correction(image, k, x_0)\n",
    "    return sig\n",
    "\n",
    "def enhance_edges(image):\n",
    "    image = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    image = np.uint8(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_float = img_as_float(image)\n",
    "    \n",
    "    # Define the structuring element (kernel) for morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 50))\n",
    "\n",
    "    # Apply the Top-Hat transformation\n",
    "    top_hat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel) \n",
    "\n",
    "    # Apply the Bottom-Hat transformation\n",
    "    bottom_hat = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)\n",
    "    \n",
    "    # Enhance the image by adding Top-Hat and subtracting Bottom-Hat\n",
    "    enhanced_image = cv2.add(image, top_hat)\n",
    "    enhanced_image = cv2.subtract(enhanced_image, bottom_hat)\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "def gab(image):\n",
    "    img = enhance_edges(image)\n",
    "    filt_real, filt_imaginary = gabor(img, 1/4, 30, sigma_x=1, sigma_y=1)\n",
    "    return filt_real\n",
    "\n",
    "def refine_edges(image):\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    center = (int(image.shape[1] / 2), int(image.shape[0] / 2))\n",
    "    radius = image.shape[1] // 2 - 1\n",
    "    cv2.circle(mask, center, radius, 255, -1)\n",
    "    result = cv2.bitwise_and(mask, image)\n",
    "    return result\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def process_images_in_folders(input_folder, output_folder):\n",
    "    # Get a list of all files to process for progress tracking\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "                all_files.append((root, file))\n",
    "\n",
    "    # Use tqdm to show progress across all images\n",
    "    for root, file in tqdm(all_files, desc=\"Processing Images\"):\n",
    "        image_path = os.path.join(root, file)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error reading {image_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.resize(image, size, interpolation=cv2.INTER_AREA)\n",
    "        # Apply Gabor filter and refine edges\n",
    "        gabor_image = gab(image)\n",
    "        refined_image = refine_edges(gabor_image)\n",
    "        \n",
    "        x = np.array(refined_image, dtype=np.uint8)\n",
    "        \n",
    "        # Create corresponding output directory\n",
    "        relative_path = os.path.relpath(root, input_folder)\n",
    "        save_dir = os.path.join(output_folder, relative_path)\n",
    "        create_dir(save_dir)\n",
    "        \n",
    "        # Save the processed image\n",
    "        save_path = os.path.join(save_dir, file)\n",
    "        cv2.imwrite(save_path, x)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"Data\"\n",
    "    output_folder = \"Data_gabor\"\n",
    "\n",
    "    # Process images and save them to the output folder\n",
    "    process_images_in_folders(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Hist Eq to channels separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 2000/2000 [00:27<00:00, 71.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate\n",
    "from skimage import img_as_float\n",
    "from skimage.filters import gabor\n",
    "from PIL import Image\n",
    "\n",
    "size = (512, 512)\n",
    "\n",
    "def apply_hist_eq(image):\n",
    "    # Split the image into its respective channels\n",
    "    channels = cv2.split(image)\n",
    "    \n",
    "    # Apply histogram equalization on each channel\n",
    "    equalized_channels = [cv2.equalizeHist(channel) for channel in channels]\n",
    "    \n",
    "    # Merge the equalized channels back into a single image\n",
    "    equalized_image = cv2.merge(equalized_channels)\n",
    "    \n",
    "    return equalized_image\n",
    "\n",
    "def enhance_edges(image):\n",
    "    image = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    image = np.uint8(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_float = img_as_float(image)\n",
    "    \n",
    "    # Define the structuring element (kernel) for morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 50))\n",
    "\n",
    "    # Apply the Top-Hat transformation\n",
    "    top_hat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel) \n",
    "\n",
    "    # Apply the Bottom-Hat transformation\n",
    "    bottom_hat = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)\n",
    "    \n",
    "    # Enhance the image by adding Top-Hat and subtracting Bottom-Hat\n",
    "    enhanced_image = cv2.add(image, top_hat)\n",
    "    enhanced_image = cv2.subtract(enhanced_image, bottom_hat)\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "def gab(image):\n",
    "    img = enhance_edges(image)\n",
    "    filt_real, filt_imaginary = gabor(img, 1/4, 30, sigma_x=1, sigma_y=1)\n",
    "    return filt_real\n",
    "\n",
    "def refine_edges(image):\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    center = (int(image.shape[1] / 2), int(image.shape[0] / 2))\n",
    "    radius = image.shape[1] // 2 - 1\n",
    "    cv2.circle(mask, center, radius, 255, -1)\n",
    "    result = cv2.bitwise_and(mask, image)\n",
    "    return result\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def process_images_in_folders(input_folder, output_folder):\n",
    "    # Get a list of all files to process for progress tracking\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "                all_files.append((root, file))\n",
    "\n",
    "    # Use tqdm to show progress across all images\n",
    "    for root, file in tqdm(all_files, desc=\"Processing Images\"):\n",
    "        image_path = os.path.join(root, file)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error reading {image_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.resize(image, size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Apply histogram equalization to all channels\n",
    "        equalized_image = apply_hist_eq(image)\n",
    "\n",
    "        # # Apply Gabor filter and refine edges\n",
    "        # gabor_image = gab(equalized_image)\n",
    "        # refined_image = refine_edges(gabor_image)\n",
    "        \n",
    "        x = np.array(equalized_image, dtype=np.uint8)\n",
    "        \n",
    "        # Create corresponding output directory\n",
    "        relative_path = os.path.relpath(root, input_folder)\n",
    "        save_dir = os.path.join(output_folder, relative_path)\n",
    "        create_dir(save_dir)\n",
    "        \n",
    "        # Save the processed image\n",
    "        save_path = os.path.join(save_dir, file)\n",
    "        cv2.imwrite(save_path, x)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"Data\"\n",
    "    output_folder = \"Data_histEq\"\n",
    "\n",
    "    # Process images and save them to the output folder\n",
    "    process_images_in_folders(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Split the data into train-val for YOLO V5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed NO_ROP: 640 train, 160 val images\n",
      "Processed ROP: 960 train, 240 val images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def split_dataset(dataset_dir, output_dir, train_ratio=0.8):\n",
    "    # Create train and validation directories\n",
    "    train_dir = os.path.join(output_dir, 'train')\n",
    "    val_dir = os.path.join(output_dir, 'val')\n",
    "    create_dir(train_dir)\n",
    "    create_dir(val_dir)\n",
    "\n",
    "    # Loop through each subfolder in the dataset\n",
    "    for folder in os.listdir(dataset_dir):\n",
    "        folder_path = os.path.join(dataset_dir, folder)\n",
    "\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Get all images in the subfolder\n",
    "            images = [img for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg', '.tif'))]\n",
    "\n",
    "            # Shuffle the images randomly\n",
    "            random.shuffle(images)\n",
    "\n",
    "            # Calculate the train/val split index\n",
    "            split_idx = int(len(images) * train_ratio)\n",
    "\n",
    "            # Create subdirectories in train and val directories\n",
    "            train_subdir = os.path.join(train_dir, folder)\n",
    "            val_subdir = os.path.join(val_dir, folder)\n",
    "            create_dir(train_subdir)\n",
    "            create_dir(val_subdir)\n",
    "\n",
    "            # Copy images to train and val directories\n",
    "            for i, img in enumerate(images):\n",
    "                img_path = os.path.join(folder_path, img)\n",
    "\n",
    "                if i < split_idx:\n",
    "                    shutil.copy(img_path, train_subdir)\n",
    "                else:\n",
    "                    shutil.copy(img_path, val_subdir)\n",
    "\n",
    "            print(f\"Processed {folder}: {split_idx} train, {len(images) - split_idx} val images\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_dir = r'Data_Rop_noRop'  # Replace with your dataset path\n",
    "    output_dir = r'Data_Rop_noRop_new'  # Replace with the output path\n",
    "    train_ratio = 0.8  # Train/Validation split ratio (80% train, 20% validation)\n",
    "\n",
    "    split_dataset(dataset_dir, output_dir, train_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To RENAME the files starting from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "def rename_and_store_images(input_folder, output_folder):\n",
    "    try:\n",
    "        # Check if input folder exists\n",
    "        if not os.path.exists(input_folder):\n",
    "            raise FileNotFoundError(f\"Input folder '{input_folder}' does not exist.\")\n",
    "        \n",
    "        # Create output folder if it doesn't exist\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        # Get list of all files in the input folder\n",
    "        images = os.listdir(input_folder)\n",
    "        \n",
    "        # Filter out non-files and hidden files (starting with '._' or '.')\n",
    "        images = [f for f in images if os.path.isfile(os.path.join(input_folder, f)) and not f.startswith('._') and not f.startswith('.')]\n",
    "        \n",
    "        # Sort the images if needed (optional)\n",
    "        images.sort()\n",
    "\n",
    "        if not images:\n",
    "            print(f\"No valid images found in folder: {input_folder}\")\n",
    "            return\n",
    "\n",
    "        # Rename and store images in the output folder with tqdm progress bar\n",
    "        for i, filename in enumerate(tqdm(images, desc=\"Renaming images\"), start=1):\n",
    "            file_extension = os.path.splitext(filename)[1]  # Keep the original extension\n",
    "            new_filename = f\"{i}{file_extension}\"  # Rename starting from 1\n",
    "            old_file_path = os.path.join(input_folder, filename)\n",
    "            new_file_path = os.path.join(output_folder, new_filename)\n",
    "            \n",
    "            # Copy and rename the file\n",
    "            shutil.copy(old_file_path, new_file_path)\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        print(fnf_error)\n",
    "    except PermissionError:\n",
    "        print(\"Permission denied. Ensure you have the right permissions for the folders.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "input_folder = r\"Data\\FVR\"\n",
    "output_folder = r\"Data\\FVR_new\"\n",
    "rename_and_store_images(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To remove HIDDEN Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_hidden_files(root_folder):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            # Check if the file is hidden (starts with '._' or '.')\n",
    "            if filename.startswith('._') or filename.startswith('.'):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"Removed hidden file: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing file {file_path}: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "root_folder = 'Data'\n",
    "remove_hidden_files(root_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (R, G, B): (0.4970856163948774, 0.3660721661299467, 0.012605847830753192)\n",
      "Standard Deviation (R, G, B): (0.3098917880987543, 0.251007258041955, 0.08280670520288899)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Function to compute mean and standard deviation for RGB channels\n",
    "def calculate_rgb_mean_std(image_folder):\n",
    "    mean_r, mean_g, mean_b = 0.0, 0.0, 0.0\n",
    "    std_r, std_g, std_b = 0.0, 0.0, 0.0\n",
    "    num_pixels = 0\n",
    "\n",
    "    # Transform to convert PIL image to tensor\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # Loop through each folder and image\n",
    "    for root, _, filenames in os.walk(image_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(('png', 'jpg', 'jpeg')):  # Ensure it's an image file\n",
    "                img_path = os.path.join(root, filename)\n",
    "                image = Image.open(img_path).convert('RGB')  # Ensure image is in RGB format\n",
    "                img_tensor = transform(image)  # Convert image to tensor (C x H x W)\n",
    "                \n",
    "                # Sum all the RGB values separately\n",
    "                mean_r += img_tensor[0].sum().item()\n",
    "                mean_g += img_tensor[1].sum().item()\n",
    "                mean_b += img_tensor[2].sum().item()\n",
    "                \n",
    "                # Sum of squared values for standard deviation calculation\n",
    "                std_r += (img_tensor[0] ** 2).sum().item()\n",
    "                std_g += (img_tensor[1] ** 2).sum().item()\n",
    "                std_b += (img_tensor[2] ** 2).sum().item()\n",
    "                \n",
    "                # Count the total number of pixels\n",
    "                num_pixels += img_tensor[0].numel()  # Number of pixels in one channel\n",
    "\n",
    "    # Calculate mean\n",
    "    mean_r /= num_pixels\n",
    "    mean_g /= num_pixels\n",
    "    mean_b /= num_pixels\n",
    "\n",
    "    # Calculate standard deviation\n",
    "    std_r = np.sqrt(std_r / num_pixels - mean_r ** 2)\n",
    "    std_g = np.sqrt(std_g / num_pixels - mean_g ** 2)\n",
    "    std_b = np.sqrt(std_b / num_pixels - mean_b ** 2)\n",
    "\n",
    "    return (mean_r, mean_g, mean_b), (std_r, std_g, std_b)\n",
    "\n",
    "# Example usage\n",
    "image_folder = 'Data_superposed'  # Replace with your image directory\n",
    "mean, std = calculate_rgb_mean_std(image_folder)\n",
    "\n",
    "print(f'Mean (R, G, B): {mean}')\n",
    "print(f'Standard Deviation (R, G, B): {std}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
