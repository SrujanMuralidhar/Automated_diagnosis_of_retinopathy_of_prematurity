{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image, ImageEnhance\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "\n",
    "# # Predicts the mask and then superposes that on the original image\n",
    "\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "\n",
    "# model = model.build_unet()\n",
    "# model.load_state_dict(torch.load(r'files\\bv_sig_G_clahe.pth', map_location=torch.device('cuda')))\n",
    "# model.eval()\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "\n",
    "# def load_image(image_path):\n",
    "#     image = Image.open(image_path).convert('RGB')\n",
    "#     image = image.resize((512, 512))\n",
    "#     image = transform(image).unsqueeze(0)\n",
    "#     return image\n",
    "\n",
    "\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         output = mask_parse(output)\n",
    "\n",
    "#     return output\n",
    "\n",
    "\n",
    "# def superimpose_mask_on_image(image_path, predicted_mask):\n",
    "#     original_image = Image.open(image_path).convert('RGB').resize((512, 512))\n",
    "    \n",
    "#     # Convert predicted mask to RGBA where the mask is highlighted in red\n",
    "#     mask_rgba = Image.fromarray(predicted_mask * 255).convert(\"RGBA\")\n",
    "#     mask_rgba_np = np.array(mask_rgba)\n",
    "\n",
    "#     # Highlight mask region by making it red\n",
    "#     mask_rgba_np[..., 0] = 255  # Red channel\n",
    "#     mask_rgba_np[..., 1] = 0    # Green channel\n",
    "#     mask_rgba_np[..., 2] = 0    # Blue channel\n",
    "#     mask_rgba_np[..., 3] = (predicted_mask[..., 0] * 128).astype(np.uint8)  # Transparency\n",
    "\n",
    "#     mask_rgba = Image.fromarray(mask_rgba_np)\n",
    "\n",
    "#     # Superimpose mask onto the original image\n",
    "#     blended_image = Image.alpha_composite(original_image.convert(\"RGBA\"), mask_rgba)\n",
    "\n",
    "#     return blended_image\n",
    "\n",
    "\n",
    "\n",
    "# image_path = r'new_data\\test\\image\\3 (2)_0.png'\n",
    "# image_tensor = load_image(image_path)\n",
    "\n",
    "# # Get the predicted mask\n",
    "# predicted_mask = get_prediction(model, image_tensor)\n",
    "\n",
    "# # Superimpose the mask on the original image\n",
    "# superimposed_image = superimpose_mask_on_image(image_path, predicted_mask)\n",
    "\n",
    "# # Save the final superimposed image\n",
    "# superimposed_image.save(f'superimposed_image_new.png')\n",
    "\n",
    "# print(\"Superimposed image saved as 'superimposed_image.png'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the mask for an entire folder\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "\n",
    "# # Parse mask for saving\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "# # Load model\n",
    "# model = model.build_unet()\n",
    "# model.load_state_dict(torch.load(r'files\\ridge_gabor.pth', map_location=torch.device('cuda')))\n",
    "# model.eval()\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# # Load and resize the image\n",
    "# def load_image(image_path):\n",
    "#     image = Image.open(image_path).convert('RGB')\n",
    "#     image = image.resize((512, 512))\n",
    "#     image = transform(image).unsqueeze(0)\n",
    "#     return image\n",
    "\n",
    "# # Get mask prediction\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         output = mask_parse(output)\n",
    "#     return output\n",
    "\n",
    "# # Main folder paths\n",
    "# image_folder = r'new_data_ridge\\test\\to_send'  # Folder with images\n",
    "# mask_output_folder = r'output'  # Folder where predicted masks will be saved\n",
    "\n",
    "# # Create output folder if it doesn't exist\n",
    "# if not os.path.exists(mask_output_folder):\n",
    "#     os.mkdir(mask_output_folder)\n",
    "\n",
    "# # Iterate through images in the image folder\n",
    "# for image_name in os.listdir(image_folder):\n",
    "#     image_path = os.path.join(image_folder, image_name)\n",
    "    \n",
    "#     # Load the image and predict the mask\n",
    "#     image_tensor = load_image(image_path)\n",
    "#     predicted_mask = get_prediction(model, image_tensor)\n",
    "    \n",
    "#     # Convert predicted mask to image format for saving\n",
    "#     predicted_mask_image = Image.fromarray((predicted_mask * 255).astype(np.uint8))\n",
    "    \n",
    "#     # Save the predicted mask\n",
    "#     mask_save_path = os.path.join(mask_output_folder, f\"mask_{image_name}\")\n",
    "#     predicted_mask_image.save(mask_save_path)\n",
    "    \n",
    "#     print(f\"Saved mask for {image_name} at {mask_save_path}\")\n",
    "\n",
    "# print(\"Mask generation and saving complete.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "\n",
    "# # Parse mask for saving\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "# # Load model\n",
    "# model = model.build_unet()\n",
    "# model.load_state_dict(torch.load(r'files\\bv_no_enhancement_no_aug.pth', map_location=torch.device('cuda')))\n",
    "# model.eval()\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# # Load and resize the image\n",
    "# def load_image(image_path):\n",
    "#     image = Image.open(image_path).convert('RGB')\n",
    "#     image = image.resize((512, 512))\n",
    "#     image = transform(image).unsqueeze(0)\n",
    "#     return image\n",
    "\n",
    "# # Load ground truth mask\n",
    "# def load_mask(mask_path):\n",
    "#     mask = Image.open(mask_path).convert('L')  # Assuming mask is grayscale\n",
    "#     mask = mask.resize((512, 512))\n",
    "#     mask = np.stack([mask]*3, axis=-1)  # Convert to 3 channels\n",
    "#     return Image.fromarray(mask)\n",
    "\n",
    "# # Get mask prediction\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         output = mask_parse(output)\n",
    "#     return output\n",
    "\n",
    "# # Concatenate original image, ground truth, and predicted mask with padding in between\n",
    "# def concatenate_images(original_image, ground_truth_mask, predicted_mask, padding=10, padding_color=(255, 255, 255)):\n",
    "#     # Create padding image (gap between images)\n",
    "#     pad = Image.new('RGB', (padding, original_image.height), padding_color)\n",
    "    \n",
    "#     # Create a new image with the correct width to accommodate the 3 images and 2 paddings\n",
    "#     total_width = original_image.width * 3 + padding * 2\n",
    "#     concatenated_image = Image.new('RGB', (total_width, original_image.height))\n",
    "    \n",
    "#     # Paste the original image, ground truth mask, and predicted mask with padding in between\n",
    "#     concatenated_image.paste(original_image, (0, 0))\n",
    "#     concatenated_image.paste(pad, (original_image.width, 0))\n",
    "#     concatenated_image.paste(ground_truth_mask, (original_image.width + padding, 0))\n",
    "#     concatenated_image.paste(pad, (original_image.width * 2 + padding, 0))\n",
    "#     concatenated_image.paste(predicted_mask, (original_image.width * 2 + padding * 2, 0))\n",
    "    \n",
    "#     return concatenated_image\n",
    "\n",
    "# # Main folder paths\n",
    "# image_folder = r'new_data\\test\\image'  # Folder with images\n",
    "# ground_truth_folder = r'new_data\\test\\mask'  # Folder with ground truth masks\n",
    "# output_folder = r'output'  # Folder where concatenated images will be saved\n",
    "\n",
    "# # Create output folder if it doesn't exist\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.mkdir(output_folder)\n",
    "\n",
    "# # Iterate through images in the image folder\n",
    "# for image_name in os.listdir(image_folder):\n",
    "#     image_path = os.path.join(image_folder, image_name)\n",
    "#     ground_truth_path = os.path.join(ground_truth_folder, image_name)  # Assuming same name for ground truth masks\n",
    "    \n",
    "#     # Load the image, ground truth mask, and predict the mask\n",
    "#     image_tensor = load_image(image_path)\n",
    "#     original_image = Image.open(image_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "#     predicted_mask = get_prediction(model, image_tensor)\n",
    "#     predicted_mask_image = Image.fromarray((predicted_mask * 255).astype(np.uint8))  # Convert predicted mask to image format\n",
    "    \n",
    "#     ground_truth_mask = load_mask(ground_truth_path)  # Load ground truth mask\n",
    "    \n",
    "#     # Concatenate images with padding\n",
    "#     concatenated_image = concatenate_images(original_image, ground_truth_mask, predicted_mask_image, padding=20)  # Adjust padding size as needed\n",
    "    \n",
    "#     # Save the concatenated image\n",
    "#     concatenated_save_path = os.path.join(output_folder, f\"concatenated_{image_name}\")\n",
    "#     concatenated_image.save(concatenated_save_path)\n",
    "    \n",
    "#     print(f\"Saved concatenated image for {image_name} at {concatenated_save_path}\")\n",
    "\n",
    "# print(\"Concatenation and saving complete.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "\n",
    "# # Parse mask for saving\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "# # Load models\n",
    "# bv_model = model.build_unet()\n",
    "# bv_model.load_state_dict(torch.load(r'files\\bv_no_enhancement.pth', map_location=torch.device('cuda')))\n",
    "# bv_model.eval()\n",
    "\n",
    "# ridge_model = model.build_unet()\n",
    "# ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "# ridge_model.eval()\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# # Load and resize the image\n",
    "# def load_image(image_path):\n",
    "#     image = Image.open(image_path).convert('RGB')\n",
    "#     image = image.resize((512, 512))\n",
    "#     image = transform(image).unsqueeze(0)\n",
    "#     return image\n",
    "\n",
    "# # Get mask prediction\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         return output\n",
    "\n",
    "# # Superpose masks on the original image\n",
    "# def superpose_masks(original_image, bv_mask, ridge_mask):\n",
    "#     # Initialize the combined mask with 3 channels (for RGB)\n",
    "#     combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "#     # Color the blood vessel mask in red\n",
    "#     combined_mask[bv_mask == 1] = [255, 0, 0]  # Red channel\n",
    "    \n",
    "#     # Color the ridge mask in blue\n",
    "#     combined_mask[ridge_mask == 1] = [0, 0, 255]  # Blue channel\n",
    "    \n",
    "#     # Convert original image to NumPy\n",
    "#     original_image_np = np.array(original_image)\n",
    "    \n",
    "#     # Superpose the masks on the original image\n",
    "#     superposed_image = original_image_np.copy()\n",
    "#     mask_indices = combined_mask > 0\n",
    "#     superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "    \n",
    "#     return Image.fromarray(superposed_image)\n",
    "\n",
    "# # Main folder paths\n",
    "# image_folder = r'Data_BV\\test_image'  # Folder with images\n",
    "# output_folder = r'output'  # Folder where superposed images will be saved\n",
    "\n",
    "# # Create output folder if it doesn't exist\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.mkdir(output_folder)\n",
    "\n",
    "# # Iterate through images in the image folder\n",
    "# for image_name in os.listdir(image_folder):\n",
    "#     image_path = os.path.join(image_folder, image_name)\n",
    "    \n",
    "#     # Load the image and predict masks for blood vessel and ridge\n",
    "#     image_tensor = load_image(image_path)\n",
    "#     original_image = Image.open(image_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "    \n",
    "#     bv_mask = get_prediction(bv_model, image_tensor)  # Blood vessel mask\n",
    "#     ridge_mask = get_prediction(ridge_model, image_tensor)  # Ridge mask\n",
    "    \n",
    "#     # Superpose the masks onto the original image\n",
    "#     superposed_image = superpose_masks(original_image, bv_mask, ridge_mask)\n",
    "    \n",
    "#     # Save the superposed image\n",
    "#     superposed_save_path = os.path.join(output_folder, f\"superposed_{image_name}\")\n",
    "#     superposed_image.save(superposed_save_path)\n",
    "    \n",
    "#     print(f\"Saved superposed image for {image_name} at {superposed_save_path}\")\n",
    "\n",
    "# print(\"Superposition and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "# from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# # Parse mask for saving\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "# # Load models\n",
    "# bv_model = model.build_unet()\n",
    "# bv_model.load_state_dict(torch.load(r'files\\bv_no_enhancement.pth', map_location=torch.device('cuda')))\n",
    "# bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "# bv_model.eval()\n",
    "\n",
    "# ridge_model = model.build_unet()\n",
    "# ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "# ridge_model = ridge_model.cuda()  # Load model on GPU if available\n",
    "# ridge_model.eval()\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# # Load and resize the image\n",
    "# def load_image(image_path):\n",
    "#     if image_path.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "#         image = Image.open(image_path).convert('RGB')\n",
    "#         image = image.resize((512, 512))\n",
    "#         image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "#         return image\n",
    "    \n",
    "# # Get mask prediction\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         return output\n",
    "\n",
    "# # Superpose masks on the original image\n",
    "# def superpose_masks(original_image, bv_mask, ridge_mask):\n",
    "#     # Initialize the combined mask with 3 channels (for RGB)\n",
    "#     combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "#     # Color the blood vessel mask in red\n",
    "#     combined_mask[bv_mask == 1] = [255, 0, 0]  # Red channel\n",
    "    \n",
    "#     # Color the ridge mask in blue\n",
    "#     combined_mask[ridge_mask == 1] = [0, 0, 255]  # Blue channel\n",
    "    \n",
    "#     # Convert original image to NumPy\n",
    "#     original_image_np = np.array(original_image)\n",
    "    \n",
    "#     # Superpose the masks on the original image\n",
    "#     superposed_image = original_image_np.copy()\n",
    "#     mask_indices = combined_mask > 0\n",
    "#     superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "    \n",
    "#     return Image.fromarray(superposed_image)\n",
    "\n",
    "# # Function to recursively process all images in subfolders\n",
    "# def process_folders(bv_input_folder, ridge_input_folder, output_folder):\n",
    "#     # Create output folder if it doesn't exist\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "    \n",
    "#     # List all items in the blood vessel folder\n",
    "#     bv_items = os.listdir(bv_input_folder)\n",
    "    \n",
    "#     # Use tqdm for progress bar when processing the items\n",
    "#     for bv_item in tqdm(bv_items, desc=\"Processing Folders\"):\n",
    "#         bv_item_path = os.path.join(bv_input_folder, bv_item)\n",
    "#         ridge_item_path = os.path.join(ridge_input_folder, bv_item)  # Assume ridge folder has the same structure\n",
    "#         output_item_path = os.path.join(output_folder, bv_item)\n",
    "\n",
    "#         if os.path.isdir(bv_item_path):\n",
    "#             # If the item is a subfolder, recursively process it\n",
    "#             process_folders(bv_item_path, ridge_item_path, output_item_path)\n",
    "#         else:\n",
    "#             # If the item is an image, check if ridge image exists\n",
    "#             if not os.path.exists(ridge_item_path):\n",
    "#                 print(f\"Ridge image not found for {bv_item}. Skipping.\")\n",
    "#                 continue\n",
    "            \n",
    "#             bv_image_tensor = load_image(bv_item_path)  # Blood vessel image\n",
    "#             ridge_image_tensor = load_image(ridge_item_path)  # Ridge image\n",
    "            \n",
    "#             original_image = Image.open(bv_item_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "            \n",
    "#             bv_mask = get_prediction(bv_model, bv_image_tensor)  # Blood vessel mask\n",
    "#             ridge_mask = get_prediction(ridge_model, ridge_image_tensor)  # Ridge mask\n",
    "            \n",
    "#             # Superpose the masks onto the original image\n",
    "#             superposed_image = superpose_masks(original_image, bv_mask, ridge_mask)\n",
    "            \n",
    "#             # Save the superposed image\n",
    "#             output_folder_path = os.path.dirname(output_item_path)\n",
    "#             if not os.path.exists(output_folder_path):\n",
    "#                 os.makedirs(output_folder_path)\n",
    "#             superposed_image.save(output_item_path)\n",
    "            \n",
    "#             print(f\"Saved superposed image for {bv_item} at {output_item_path}\")\n",
    "\n",
    "# # Main input and output folder paths\n",
    "\n",
    "# bv_input_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data'  # Folder for blood vessel images\n",
    "\n",
    "# ridge_input_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data_gabor'  # Folder for ridge images\n",
    "\n",
    "# main_output_folder = r'output'  # Folder where superposed images will be saved\n",
    "\n",
    "# # Start processing the main folder\n",
    "# process_folders(bv_input_folder, ridge_input_folder, main_output_folder)\n",
    "\n",
    "# print(\"Superposition and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import model\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Parse mask for saving\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "    return mask\n",
    "\n",
    "# Load models\n",
    "bv_model = model.build_unet()\n",
    "bv_model.load_state_dict(torch.load(r'files\\bv_no_enhancement.pth', map_location=torch.device('cuda')))\n",
    "bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "bv_model.eval()\n",
    "\n",
    "ridge_model = model.build_unet()\n",
    "ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "ridge_model = ridge_model.cuda()  # Load model on GPU if available\n",
    "ridge_model.eval()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load and resize the image\n",
    "def load_image(image_path):\n",
    "    if image_path.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image.resize((512, 512))\n",
    "        image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "        return image\n",
    "    \n",
    "# Get mask prediction\n",
    "def get_prediction(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "        output = np.squeeze(output, axis=0)\n",
    "        output = output > 0.5\n",
    "        output = np.array(output, dtype=np.uint8)\n",
    "        return output\n",
    "\n",
    "def sigmoid_correction(image, k=10, x0=0.5):\n",
    "    # Normalize the image\n",
    "    normalized_img = image / 255.0\n",
    "    # Apply the sigmoid function\n",
    "    sigmoid_img = 1 / (1 + np.exp(-k * (normalized_img - x0)))\n",
    "    # Scale back to original range\n",
    "    corrected_img = (sigmoid_img * 255).astype(np.uint8)\n",
    "    return corrected_img\n",
    "\n",
    "\n",
    "def adaptive_sigmoid(image):\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    center = (int(image.shape[1] / 2), int(image.shape[0] / 2))\n",
    "    radius = image.shape[1]//2\n",
    "    cv2.circle(mask, center, radius, 255, -1)\n",
    "    hist = cv2.calcHist([image], [1], mask, [256], [0, 256])\n",
    "    # Calculate cumulative distribution function (CDF)\n",
    "    cdf = hist.cumsum()\n",
    "    # Normalize CDF\n",
    "    cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "    # Find the intensity level where CDF reaches 50% of the total pixel count\n",
    "    total_pixels = cdf[-1]\n",
    "    x_0 = np.searchsorted(cdf, total_pixels * 0.5)/255\n",
    "    k = 15\n",
    "    sig = sigmoid_correction(image,k,x_0)\n",
    "    return sig\n",
    "\n",
    "def apply_hist_eq(image):\n",
    "    # Split the image into its respective channels\n",
    "    channels = cv2.split(image)\n",
    "    \n",
    "    # Apply histogram equalization on each channel\n",
    "    equalized_channels = [cv2.equalizeHist(channel) for channel in channels]\n",
    "    \n",
    "    # Merge the equalized channels back into a single image\n",
    "    equalized_image = cv2.merge(equalized_channels)\n",
    "    \n",
    "    return equalized_image\n",
    "\n",
    "# Superpose masks on the original image\n",
    "# Superpose masks on the original image with sigmoid correction\n",
    "def superpose_masks(original_image, bv_mask, ridge_mask):\n",
    "    # Convert original image to NumPy\n",
    "    original_image_np = np.array(original_image)\n",
    "    \n",
    "    # Apply sigmoid correction to the original image\n",
    "    corrected_image_np = adaptive_sigmoid(original_image_np)\n",
    "    \n",
    "    # Initialize the combined mask with 3 channels (for RGB)\n",
    "    combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # COLOR coding for the MASKS\n",
    "    #-----------------------------------------------------------------------------\n",
    "    combined_mask[bv_mask == 1] = [179, 2, 2]  \n",
    "    combined_mask[ridge_mask == 1] = [25, 10, 242]  \n",
    "    #------------------------------------------------------------------------------\n",
    "    # Superpose the masks on the sigmoid-corrected original image\n",
    "    superposed_image = corrected_image_np.copy()\n",
    "    mask_indices = combined_mask > 0\n",
    "    superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "    \n",
    "    return Image.fromarray(superposed_image)\n",
    "\n",
    "# Function to recursively process all images in subfolders\n",
    "def process_folders(bv_input_folder, ridge_input_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # List all items in the blood vessel folder\n",
    "    bv_items = os.listdir(bv_input_folder)\n",
    "    \n",
    "    # Use tqdm for progress bar when processing the items\n",
    "    for bv_item in tqdm(bv_items, desc=\"Processing Folders\"):\n",
    "        bv_item_path = os.path.join(bv_input_folder, bv_item)\n",
    "        ridge_item_path = os.path.join(ridge_input_folder, bv_item)  # Assume ridge folder has the same structure\n",
    "        output_item_path = os.path.join(output_folder, bv_item)\n",
    "\n",
    "        if os.path.isdir(bv_item_path):\n",
    "            # If the item is a subfolder, recursively process it\n",
    "            process_folders(bv_item_path, ridge_item_path, output_item_path)\n",
    "        else:\n",
    "            # If the item is an image, check if ridge image exists\n",
    "            if not os.path.exists(ridge_item_path):\n",
    "                print(f\"Ridge image not found for {bv_item}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            bv_image_tensor = load_image(bv_item_path)  # Blood vessel image\n",
    "            ridge_image_tensor = load_image(ridge_item_path)  # Ridge image\n",
    "            \n",
    "            original_image = Image.open(bv_item_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "            \n",
    "            bv_mask = get_prediction(bv_model, bv_image_tensor)  # Blood vessel mask\n",
    "            ridge_mask = get_prediction(ridge_model, ridge_image_tensor)  # Ridge mask\n",
    "            \n",
    "            # Superpose the masks onto the original image\n",
    "            superposed_image = superpose_masks(original_image, bv_mask, ridge_mask)\n",
    "            \n",
    "            # Save the superposed image\n",
    "            output_folder_path = os.path.dirname(output_item_path)\n",
    "            if not os.path.exists(output_folder_path):\n",
    "                os.makedirs(output_folder_path)\n",
    "            superposed_image.save(output_item_path)\n",
    "            \n",
    "            # print(f\"Saved superposed image for {bv_item} at {output_item_path}\")\n",
    "\n",
    "# Main input and output folder paths\n",
    "\n",
    "bv_input_folder = r'Data_BV\\train_images'  # Folder for blood vessel images\n",
    "\n",
    "ridge_input_folder = r'Data_Ridge'  # Folder for ridge images\n",
    "\n",
    "main_output_folder = r'output'  # Folder where superposed images will be saved\n",
    "\n",
    "# Start processing the main folder\n",
    "process_folders(bv_input_folder, ridge_input_folder, main_output_folder)\n",
    "\n",
    "print(\"Superposition and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "# import cv2\n",
    "# from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# # Parse mask for saving\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "# # Load models\n",
    "# bv_model = model.build_unet()\n",
    "# bv_model.load_state_dict(torch.load(r'files\\bv_perCHistEq_kaggle_data.pth', map_location=torch.device('cuda')))\n",
    "# bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "# bv_model.eval()\n",
    "\n",
    "# ridge_model = model.build_unet()\n",
    "# ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "# ridge_model = ridge_model.cuda()  # Load model on GPU if available\n",
    "# ridge_model.eval()\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# # Load and resize the image\n",
    "# def load_image(image_path):\n",
    "#     if image_path.endswith(('.png', '.jpg', '.jpeg', '.tif')): \n",
    "#         image = Image.open(image_path).convert('RGB')\n",
    "#         image = image.resize((512, 512))\n",
    "#         image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "#         return image\n",
    "    \n",
    "# # Get mask prediction\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         return output\n",
    "\n",
    "\n",
    "# # Superpose masks on the original image\n",
    "# def superpose_masks(original_image, bv_mask, ridge_mask):\n",
    "#     # Convert original image to NumPy\n",
    "#     original_image_np = np.array(original_image)\n",
    "    \n",
    "#     # Apply sigmoid correction to the original image\n",
    "#     corrected_image_np = adaptive_sigmoid(original_image_np)\n",
    "    \n",
    "#     # Initialize the combined mask with 3 channels (for RGB)\n",
    "#     combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "#     # COLOR coding for the MASKS\n",
    "#     #-----------------------------------------------------------------------------\n",
    "#     combined_mask[bv_mask == 1] = [179, 2, 2]  \n",
    "#     combined_mask[ridge_mask == 1] = [25, 10, 242]  \n",
    "#     #------------------------------------------------------------------------------\n",
    "#     # Superpose the masks on the sigmoid-corrected original image\n",
    "#     superposed_image = corrected_image_np.copy()\n",
    "#     mask_indices = combined_mask > 0\n",
    "#     superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "    \n",
    "#     return Image.fromarray(superposed_image)\n",
    "\n",
    "# # Function to recursively process all images in subfolders\n",
    "# def process_folders(bv_input_folder, ridge_input_folder, original_image_folder, output_folder):\n",
    "#     # Create output folder if it doesn't exist\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "    \n",
    "#     # List all items in the blood vessel folder\n",
    "#     bv_items = os.listdir(bv_input_folder)\n",
    "    \n",
    "#     # Use tqdm for progress bar when processing the items\n",
    "#     for bv_item in tqdm(bv_items, desc=\"Processing Folders\"):\n",
    "#         bv_item_path = os.path.join(bv_input_folder, bv_item)\n",
    "#         ridge_item_path = os.path.join(ridge_input_folder, bv_item)  # Assume ridge folder has the same structure\n",
    "#         original_image_path = os.path.join(original_image_folder, bv_item)  # Get the original image\n",
    "#         output_item_path = os.path.join(output_folder, bv_item)\n",
    "\n",
    "#         if os.path.isdir(bv_item_path):\n",
    "#             # If the item is a subfolder, recursively process it\n",
    "#             process_folders(bv_item_path, ridge_item_path, original_image_path, output_item_path)\n",
    "#         else:\n",
    "#             # If the item is an image, check if ridge and original images exist\n",
    "#             if not os.path.exists(ridge_item_path) or not os.path.exists(original_image_path):\n",
    "#                 print(f\"Ridge or original image not found for {bv_item}. Skipping.\")\n",
    "#                 continue\n",
    "            \n",
    "#             bv_image_tensor = load_image(bv_item_path)  # Blood vessel image\n",
    "#             ridge_image_tensor = load_image(ridge_item_path)  # Ridge image\n",
    "#             original_image = Image.open(original_image_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "            \n",
    "#             bv_mask = get_prediction(bv_model, bv_image_tensor)  # Blood vessel mask\n",
    "#             ridge_mask = get_prediction(ridge_model, ridge_image_tensor)  # Ridge mask\n",
    "            \n",
    "#             # Superpose the masks onto the original image\n",
    "#             superposed_image = superpose_masks(original_image, bv_mask, ridge_mask)\n",
    "            \n",
    "#             # Save the superposed image\n",
    "#             output_folder_path = os.path.dirname(output_item_path)\n",
    "#             if not os.path.exists(output_folder_path):\n",
    "#                 os.makedirs(output_folder_path)\n",
    "#             superposed_image.save(output_item_path)\n",
    "            \n",
    "#             # print(f\"Saved superposed image for {bv_item} at {output_item_path}\")\n",
    "\n",
    "# # Main input and output folder paths\n",
    "\n",
    "# bv_input_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data_histEq'  # Folder for blood vessel images\n",
    "# ridge_input_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data_gabor'  # Folder for ridge images\n",
    "# original_image_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data'  # Folder for original images\n",
    "# main_output_folder = r'output'  # Folder where superposed images will be saved\n",
    "\n",
    "# # Start processing the main folder\n",
    "# process_folders(bv_input_folder, ridge_input_folder, original_image_folder, main_output_folder)\n",
    "\n",
    "# print(\"Superposition and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xerom\\AppData\\Local\\Temp\\ipykernel_2052\\2411054369.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bv_model.load_state_dict(torch.load(r'files\\bv_no_enhancement.pth', map_location=torch.device('cuda')))\n",
      "C:\\Users\\xerom\\AppData\\Local\\Temp\\ipykernel_2052\\2411054369.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
      "Processing Folders:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 1.png at output_concat\\FVR\\1.png\n",
      "Saved concatenated image for 10.png at output_concat\\FVR\\10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 100.png at output_concat\\FVR\\100.png\n",
      "Saved concatenated image for 101.png at output_concat\\FVR\\101.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:   1%|          | 4/400 [00:00<01:15,  5.24it/s]\u001b[A\n",
      "Processing Folders:   2%|▏         | 6/400 [00:01<01:13,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 102.png at output_concat\\FVR\\102.png\n",
      "Saved concatenated image for 103.png at output_concat\\FVR\\103.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 104.png at output_concat\\FVR\\104.png\n",
      "Saved concatenated image for 105.png at output_concat\\FVR\\105.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:   2%|▏         | 8/400 [00:01<01:12,  5.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 106.png at output_concat\\FVR\\106.png\n",
      "Saved concatenated image for 107.png at output_concat\\FVR\\107.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:   2%|▎         | 10/400 [00:01<01:11,  5.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 108.png at output_concat\\FVR\\108.png\n",
      "Saved concatenated image for 109.png at output_concat\\FVR\\109.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 11.png at output_concat\\FVR\\11.png\n",
      "Saved concatenated image for 110.png at output_concat\\FVR\\110.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 111.png at output_concat\\FVR\\111.png\n",
      "Saved concatenated image for 112.png at output_concat\\FVR\\112.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 113.png at output_concat\\FVR\\113.png\n",
      "Saved concatenated image for 114.png at output_concat\\FVR\\114.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 115.png at output_concat\\FVR\\115.png\n",
      "Saved concatenated image for 116.png at output_concat\\FVR\\116.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:   5%|▌         | 20/400 [00:03<01:09,  5.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 117.png at output_concat\\FVR\\117.png\n",
      "Saved concatenated image for 118.png at output_concat\\FVR\\118.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:   6%|▌         | 22/400 [00:04<01:08,  5.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 119.png at output_concat\\FVR\\119.png\n",
      "Saved concatenated image for 12.png at output_concat\\FVR\\12.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 120.png at output_concat\\FVR\\120.png\n",
      "Saved concatenated image for 121.png at output_concat\\FVR\\121.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:   6%|▋         | 26/400 [00:04<01:09,  5.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 122.png at output_concat\\FVR\\122.png\n",
      "Saved concatenated image for 123.png at output_concat\\FVR\\123.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:   7%|▋         | 28/400 [00:05<01:09,  5.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 124.png at output_concat\\FVR\\124.png\n",
      "Saved concatenated image for 125.png at output_concat\\FVR\\125.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 126.png at output_concat\\FVR\\126.png\n",
      "Saved concatenated image for 127.png at output_concat\\FVR\\127.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:   8%|▊         | 32/400 [00:05<01:08,  5.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 128.png at output_concat\\FVR\\128.png\n",
      "Saved concatenated image for 129.png at output_concat\\FVR\\129.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 13.png at output_concat\\FVR\\13.png\n",
      "Saved concatenated image for 130.png at output_concat\\FVR\\130.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 131.png at output_concat\\FVR\\131.png\n",
      "Saved concatenated image for 132.png at output_concat\\FVR\\132.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 133.png at output_concat\\FVR\\133.png\n",
      "Saved concatenated image for 134.png at output_concat\\FVR\\134.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  10%|█         | 40/400 [00:07<01:05,  5.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 135.png at output_concat\\FVR\\135.png\n",
      "Saved concatenated image for 136.png at output_concat\\FVR\\136.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 137.png at output_concat\\FVR\\137.png\n",
      "Saved concatenated image for 138.png at output_concat\\FVR\\138.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 139.png at output_concat\\FVR\\139.png\n",
      "Saved concatenated image for 14.png at output_concat\\FVR\\14.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 140.png at output_concat\\FVR\\140.png\n",
      "Saved concatenated image for 141.png at output_concat\\FVR\\141.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 142.png at output_concat\\FVR\\142.png\n",
      "Saved concatenated image for 143.png at output_concat\\FVR\\143.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  12%|█▎        | 50/400 [00:09<01:04,  5.47it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 144.png at output_concat\\FVR\\144.png\n",
      "Saved concatenated image for 145.png at output_concat\\FVR\\145.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  13%|█▎        | 52/400 [00:09<01:03,  5.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 146.png at output_concat\\FVR\\146.png\n",
      "Saved concatenated image for 147.png at output_concat\\FVR\\147.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  14%|█▎        | 54/400 [00:09<01:02,  5.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 148.png at output_concat\\FVR\\148.png\n",
      "Saved concatenated image for 149.png at output_concat\\FVR\\149.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 15.png at output_concat\\FVR\\15.png\n",
      "Saved concatenated image for 150.png at output_concat\\FVR\\150.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 151.png at output_concat\\FVR\\151.png\n",
      "Saved concatenated image for 152.png at output_concat\\FVR\\152.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 153.png at output_concat\\FVR\\153.png\n",
      "Saved concatenated image for 154.png at output_concat\\FVR\\154.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  16%|█▌        | 62/400 [00:11<01:01,  5.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 155.png at output_concat\\FVR\\155.png\n",
      "Saved concatenated image for 156.png at output_concat\\FVR\\156.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 157.png at output_concat\\FVR\\157.png\n",
      "Saved concatenated image for 158.png at output_concat\\FVR\\158.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 159.png at output_concat\\FVR\\159.png\n",
      "Saved concatenated image for 16.png at output_concat\\FVR\\16.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  17%|█▋        | 68/400 [00:12<00:59,  5.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 160.png at output_concat\\FVR\\160.png\n",
      "Saved concatenated image for 161.png at output_concat\\FVR\\161.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 162.png at output_concat\\FVR\\162.png\n",
      "Saved concatenated image for 163.png at output_concat\\FVR\\163.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 164.png at output_concat\\FVR\\164.png\n",
      "Saved concatenated image for 165.png at output_concat\\FVR\\165.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 166.png at output_concat\\FVR\\166.png\n",
      "Saved concatenated image for 167.png at output_concat\\FVR\\167.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 168.png at output_concat\\FVR\\168.png\n",
      "Saved concatenated image for 169.png at output_concat\\FVR\\169.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 17.png at output_concat\\FVR\\17.png\n",
      "Saved concatenated image for 170.png at output_concat\\FVR\\170.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  20%|██        | 80/400 [00:14<00:58,  5.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 171.png at output_concat\\FVR\\171.png\n",
      "Saved concatenated image for 172.png at output_concat\\FVR\\172.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 173.png at output_concat\\FVR\\173.png\n",
      "Saved concatenated image for 174.png at output_concat\\FVR\\174.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 175.png at output_concat\\FVR\\175.png\n",
      "Saved concatenated image for 176.png at output_concat\\FVR\\176.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 177.png at output_concat\\FVR\\177.png\n",
      "Saved concatenated image for 178.png at output_concat\\FVR\\178.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 179.png at output_concat\\FVR\\179.png\n",
      "Saved concatenated image for 18.png at output_concat\\FVR\\18.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 180.png at output_concat\\FVR\\180.png\n",
      "Saved concatenated image for 181.png at output_concat\\FVR\\181.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 182.png at output_concat\\FVR\\182.png\n",
      "Saved concatenated image for 183.png at output_concat\\FVR\\183.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  24%|██▎       | 94/400 [00:17<00:55,  5.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 184.png at output_concat\\FVR\\184.png\n",
      "Saved concatenated image for 185.png at output_concat\\FVR\\185.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  24%|██▍       | 96/400 [00:17<00:55,  5.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 186.png at output_concat\\FVR\\186.png\n",
      "Saved concatenated image for 187.png at output_concat\\FVR\\187.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 188.png at output_concat\\FVR\\188.png\n",
      "Saved concatenated image for 189.png at output_concat\\FVR\\189.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 19.png at output_concat\\FVR\\19.png\n",
      "Saved concatenated image for 190.png at output_concat\\FVR\\190.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 191.png at output_concat\\FVR\\191.png\n",
      "Saved concatenated image for 192.png at output_concat\\FVR\\192.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 193.png at output_concat\\FVR\\193.png\n",
      "Saved concatenated image for 194.png at output_concat\\FVR\\194.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 195.png at output_concat\\FVR\\195.png\n",
      "Saved concatenated image for 196.png at output_concat\\FVR\\196.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  27%|██▋       | 108/400 [00:19<00:52,  5.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 197.png at output_concat\\FVR\\197.png\n",
      "Saved concatenated image for 198.png at output_concat\\FVR\\198.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 199.png at output_concat\\FVR\\199.png\n",
      "Saved concatenated image for 2.png at output_concat\\FVR\\2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  28%|██▊       | 112/400 [00:20<00:52,  5.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 20.png at output_concat\\FVR\\20.png\n",
      "Saved concatenated image for 200.png at output_concat\\FVR\\200.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 201.png at output_concat\\FVR\\201.png\n",
      "Saved concatenated image for 202.png at output_concat\\FVR\\202.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 203.png at output_concat\\FVR\\203.png\n",
      "Saved concatenated image for 204.png at output_concat\\FVR\\204.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  30%|██▉       | 118/400 [00:21<00:50,  5.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 205.png at output_concat\\FVR\\205.png\n",
      "Saved concatenated image for 206.png at output_concat\\FVR\\206.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 207.png at output_concat\\FVR\\207.png\n",
      "Saved concatenated image for 208.png at output_concat\\FVR\\208.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 209.png at output_concat\\FVR\\209.png\n",
      "Saved concatenated image for 21.png at output_concat\\FVR\\21.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  31%|███       | 124/400 [00:22<00:50,  5.51it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 210.png at output_concat\\FVR\\210.png\n",
      "Saved concatenated image for 211.png at output_concat\\FVR\\211.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  32%|███▏      | 126/400 [00:23<00:50,  5.48it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 212.png at output_concat\\FVR\\212.png\n",
      "Saved concatenated image for 213.png at output_concat\\FVR\\213.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  32%|███▏      | 128/400 [00:23<00:48,  5.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 214.png at output_concat\\FVR\\214.png\n",
      "Saved concatenated image for 215.png at output_concat\\FVR\\215.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 216.png at output_concat\\FVR\\216.png\n",
      "Saved concatenated image for 217.png at output_concat\\FVR\\217.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 218.png at output_concat\\FVR\\218.png\n",
      "Saved concatenated image for 219.png at output_concat\\FVR\\219.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 22.png at output_concat\\FVR\\22.png\n",
      "Saved concatenated image for 220.png at output_concat\\FVR\\220.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 221.png at output_concat\\FVR\\221.png\n",
      "Saved concatenated image for 222.png at output_concat\\FVR\\222.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 223.png at output_concat\\FVR\\223.png\n",
      "Saved concatenated image for 224.png at output_concat\\FVR\\224.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 225.png at output_concat\\FVR\\225.png\n",
      "Saved concatenated image for 226.png at output_concat\\FVR\\226.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  36%|███▌      | 142/400 [00:25<00:46,  5.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 227.png at output_concat\\FVR\\227.png\n",
      "Saved concatenated image for 228.png at output_concat\\FVR\\228.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  36%|███▌      | 144/400 [00:26<00:46,  5.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 229.png at output_concat\\FVR\\229.png\n",
      "Saved concatenated image for 23.png at output_concat\\FVR\\23.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 230.png at output_concat\\FVR\\230.png\n",
      "Saved concatenated image for 231.png at output_concat\\FVR\\231.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 232.png at output_concat\\FVR\\232.png\n",
      "Saved concatenated image for 233.png at output_concat\\FVR\\233.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 234.png at output_concat\\FVR\\234.png\n",
      "Saved concatenated image for 235.png at output_concat\\FVR\\235.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 236.png at output_concat\\FVR\\236.png\n",
      "Saved concatenated image for 237.png at output_concat\\FVR\\237.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  38%|███▊      | 154/400 [00:28<00:45,  5.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 238.png at output_concat\\FVR\\238.png\n",
      "Saved concatenated image for 239.png at output_concat\\FVR\\239.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  39%|███▉      | 156/400 [00:28<00:45,  5.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 24.png at output_concat\\FVR\\24.png\n",
      "Saved concatenated image for 240.png at output_concat\\FVR\\240.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  40%|███▉      | 158/400 [00:28<00:45,  5.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concatenated image for 241.png at output_concat\\FVR\\241.png\n",
      "Saved concatenated image for 242.png at output_concat\\FVR\\242.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  40%|████      | 160/400 [00:29<00:44,  5.43it/s]\n",
      "Processing Folders:   0%|          | 0/5 [00:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\xerom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\ImageFile.py:547\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 547\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m()\n\u001b[0;32m    548\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 113\u001b[0m\n\u001b[0;32m    110\u001b[0m main_output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_concat\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Folder where concatenated images will be saved\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Start processing the main folder\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m \u001b[43mprocess_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbv_input_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mridge_input_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_output_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConcatenation and saving complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 80\u001b[0m, in \u001b[0;36mprocess_folders\u001b[1;34m(bv_input_folder, ridge_input_folder, output_folder)\u001b[0m\n\u001b[0;32m     76\u001b[0m output_item_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, bv_item)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(bv_item_path):\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# If the item is a subfolder, recursively process it\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[43mprocess_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbv_item_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mridge_item_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_item_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# If the item is an image, check if ridge image exists\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(ridge_item_path):\n",
      "Cell \u001b[1;32mIn[2], line 102\u001b[0m, in \u001b[0;36mprocess_folders\u001b[1;34m(bv_input_folder, ridge_input_folder, output_folder)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_folder_path):\n\u001b[0;32m    101\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(output_folder_path)\n\u001b[1;32m--> 102\u001b[0m \u001b[43mconcatenated_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_item_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved concatenated image for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbv_item\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_item_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\xerom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:2568\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2565\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[0;32m   2567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2568\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2569\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   2570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32mc:\\Users\\xerom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\PngImagePlugin.py:1431\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     im \u001b[38;5;241m=\u001b[39m _write_multiple_frames(\n\u001b[0;32m   1428\u001b[0m         im, fp, chunk, mode, rawmode, default_image, append_images\n\u001b[0;32m   1429\u001b[0m     )\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im:\n\u001b[1;32m-> 1431\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[1;32mc:\\Users\\xerom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\ImageFile.py:551\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    549\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 551\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    553\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\xerom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\ImageFile.py:570\u001b[0m, in \u001b[0;36m_encode_tile\u001b[1;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 570\u001b[0m         errcode, data \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    571\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[0;32m    572\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import model\n",
    "import os\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Parse mask for saving\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "    return mask\n",
    "\n",
    "# Load models\n",
    "bv_model = model.build_unet()\n",
    "bv_model.load_state_dict(torch.load(r'files\\bv_no_enhancement.pth', map_location=torch.device('cuda')))\n",
    "bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "bv_model.eval()\n",
    "\n",
    "ridge_model = model.build_unet()\n",
    "ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "ridge_model = ridge_model.cuda()  # Load model on GPU if available\n",
    "ridge_model.eval()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load and resize the image\n",
    "def load_image(image_path):\n",
    "    if image_path.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image.resize((512, 512))\n",
    "        image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "        return image\n",
    "\n",
    "# Get mask prediction\n",
    "def get_prediction(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "        output = np.squeeze(output, axis=0)\n",
    "        output = output > 0.5\n",
    "        output = np.array(output, dtype=np.uint8)\n",
    "        return output\n",
    "\n",
    "# Concatenate masks with the original image\n",
    "def concat_masks(original_image, bv_mask, ridge_mask):\n",
    "    # Convert masks to images (grayscale masks)\n",
    "    bv_mask_image = Image.fromarray(bv_mask * 255).convert('L').resize((512, 512))\n",
    "    ridge_mask_image = Image.fromarray(ridge_mask * 255).convert('L').resize((512, 512))\n",
    "    \n",
    "    # Concatenate original, blood vessel mask, and ridge mask side by side\n",
    "    concatenated_image = Image.new('RGB', (original_image.width + bv_mask_image.width + ridge_mask_image.width, 512))\n",
    "    concatenated_image.paste(original_image, (0, 0))\n",
    "    concatenated_image.paste(ridge_mask_image.convert('RGB'), (512, 0))  # Convert mask to RGB for concatenation\n",
    "    concatenated_image.paste(bv_mask_image.convert('RGB'), (1024, 0))  # Convert mask to RGB for concatenation\n",
    "   \n",
    "    \n",
    "    return concatenated_image\n",
    "\n",
    "# Function to recursively process all images in subfolders\n",
    "def process_folders(bv_input_folder, ridge_input_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # List all items in the blood vessel folder\n",
    "    bv_items = os.listdir(bv_input_folder)\n",
    "    \n",
    "    # Use tqdm for progress bar when processing the items\n",
    "    for bv_item in tqdm(bv_items, desc=\"Processing Folders\"):\n",
    "        bv_item_path = os.path.join(bv_input_folder, bv_item)\n",
    "        ridge_item_path = os.path.join(ridge_input_folder, bv_item)  # Assume ridge folder has the same structure\n",
    "        output_item_path = os.path.join(output_folder, bv_item)\n",
    "\n",
    "        if os.path.isdir(bv_item_path):\n",
    "            # If the item is a subfolder, recursively process it\n",
    "            process_folders(bv_item_path, ridge_item_path, output_item_path)\n",
    "        else:\n",
    "            # If the item is an image, check if ridge image exists\n",
    "            if not os.path.exists(ridge_item_path):\n",
    "                print(f\"Ridge image not found for {bv_item}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            bv_image_tensor = load_image(bv_item_path)  # Blood vessel image\n",
    "            ridge_image_tensor = load_image(ridge_item_path)  # Ridge image\n",
    "            \n",
    "            original_image = Image.open(bv_item_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "            \n",
    "            bv_mask = get_prediction(bv_model, bv_image_tensor)  # Blood vessel mask\n",
    "            ridge_mask = get_prediction(ridge_model, ridge_image_tensor)  # Ridge mask\n",
    "            \n",
    "            # Concatenate the masks with the original image\n",
    "            concatenated_image = concat_masks(original_image, bv_mask, ridge_mask)\n",
    "            \n",
    "            # Save the concatenated image\n",
    "            output_folder_path = os.path.dirname(output_item_path)\n",
    "            if not os.path.exists(output_folder_path):\n",
    "                os.makedirs(output_folder_path)\n",
    "            concatenated_image.save(output_item_path)\n",
    "            \n",
    "            print(f\"Saved concatenated image for {bv_item} at {output_item_path}\")\n",
    "\n",
    "# Main input and output folder paths\n",
    "\n",
    "bv_input_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data'  # Folder for blood vessel images\n",
    "ridge_input_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data_gabor'  # Folder for ridge images\n",
    "main_output_folder = r'output'  # Folder where concatenated images will be saved\n",
    "\n",
    "# Start processing the main folder\n",
    "process_folders(bv_input_folder, ridge_input_folder, main_output_folder)\n",
    "\n",
    "print(\"Concatenation and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import model\n",
    "import cv2\n",
    "\n",
    "# Load models\n",
    "bv_model = model.build_unet()\n",
    "bv_model.load_state_dict(torch.load(r'files\\bv_no_enhancement.pth', map_location=torch.device('cuda')))\n",
    "bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "bv_model.eval()\n",
    "\n",
    "ridge_model = model.build_unet()\n",
    "ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "ridge_model = ridge_model.cuda()  # Load model on GPU if available\n",
    "ridge_model.eval()\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load and resize the image\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = image.resize((512, 512))\n",
    "    image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "    return image\n",
    "\n",
    "# Get mask prediction\n",
    "def get_prediction(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "        output = np.squeeze(output, axis=0)\n",
    "        output = output > 0.5\n",
    "        output = np.array(output, dtype=np.uint8)\n",
    "        return output\n",
    "\n",
    "# Sigmoid correction functions\n",
    "def sigmoid_correction(image, k=10, x0=0.5):\n",
    "    normalized_img = image / 255.0\n",
    "    sigmoid_img = 1 / (1 + np.exp(-k * (normalized_img - x0)))\n",
    "    corrected_img = (sigmoid_img * 255).astype(np.uint8)\n",
    "    return corrected_img\n",
    "\n",
    "def adaptive_sigmoid(image):\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    center = (int(image.shape[1] / 2), int(image.shape[0] / 2))\n",
    "    radius = image.shape[1] // 2\n",
    "    cv2.circle(mask, center, radius, 255, -1)\n",
    "    hist = cv2.calcHist([image], [1], mask, [256], [0, 256])\n",
    "    cdf = hist.cumsum()\n",
    "    total_pixels = cdf[-1]\n",
    "    x_0 = np.searchsorted(cdf, total_pixels * 0.5) / 255\n",
    "    k = 15\n",
    "    sig = sigmoid_correction(image, k, x_0)\n",
    "    return sig\n",
    "\n",
    "# Superpose masks on the original image\n",
    "def superpose_masks(original_image, bv_mask, ridge_mask):\n",
    "    original_image_np = np.array(original_image)\n",
    "    corrected_image_np = adaptive_sigmoid(original_image_np)\n",
    "    combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "    combined_mask[bv_mask == 1] = [179, 2, 2]  \n",
    "    combined_mask[ridge_mask == 1] = [25, 10, 242]\n",
    "    superposed_image = corrected_image_np.copy()\n",
    "    mask_indices = combined_mask > 0\n",
    "    superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "    return Image.fromarray(superposed_image)\n",
    "\n",
    "# Function to process a single image\n",
    "def process_single_image(bv_image_path, ridge_image_path, output_path):\n",
    "    bv_image_tensor = load_image(bv_image_path)\n",
    "    ridge_image_tensor = load_image(ridge_image_path)\n",
    "    original_image = Image.open(bv_image_path).convert('RGB').resize((512, 512))\n",
    "\n",
    "    bv_mask = get_prediction(bv_model, bv_image_tensor)\n",
    "    ridge_mask = get_prediction(ridge_model, ridge_image_tensor)\n",
    "\n",
    "    superposed_image = superpose_masks(original_image, bv_mask, ridge_mask)\n",
    "    superposed_image.save(output_path)\n",
    "    print(f\"Saved superposed image at {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "bv_image_path = r'Data_BV\\train_images\\Img1 (17).png'\n",
    "ridge_image_path = r'new_data\\train\\image\\Img1 (17)_0.png'\n",
    "output_path = r'path_to_output_image.jpg'\n",
    "process_single_image(bv_image_path, ridge_image_path, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
